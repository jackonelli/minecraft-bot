{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\georg\\anaconda3\\envs\\minerl\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import minerl\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "from skimage import feature\n",
    "\n",
    "import os\n",
    "\n",
    "from mission_util import create_mission, INTERESTING_COORDS\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.optim import Adam, Adagrad\n",
    "from gym.spaces import Discrete, Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mission_name = \"outsideToEntranceDense\"\n",
    "create_mission(start_coords=INTERESTING_COORDS[\"outside_close_to_entrance\"],\n",
    "               goal_coords=INTERESTING_COORDS[\"inside_entrance\"],\n",
    "               mission_name=mission_name,\n",
    "               dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run parse_missions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import logging\n",
    "#logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_path = os.path.join(\"my_mission_xmls\", mission_name + \".xml\")\n",
    "env = gym.make(\"MineRLNavigate-v0\", xml=xml_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the environment to allow interactive connections on port 6666\n",
    "# and slow the tick speed to 6666.\n",
    "# env.make_interactive(port=6666, realtime=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = obs[\"pov\"][..., 0]\n",
    "edges = feature.canny(im, sigma=1)\n",
    "plt.imshow(edges, cmap=plt.cm.gray)\n",
    "print(im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapted from \n",
    "#https://github.com/openai/spinningup/blob/master/spinup/examples/pytorch/pg_math/1_simple_pg.py\n",
    "def mlp(sizes, activation=nn.Tanh, output_activation=nn.Identity):\n",
    "    # Build a feedforward neural network.\n",
    "    layers = []\n",
    "    for j in range(len(sizes)-1):\n",
    "        act = activation if j < len(sizes)-2 else output_activation\n",
    "        layers += [nn.Linear(sizes[j], sizes[j+1]), act()]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def train(env, logits_net = None, hidden_sizes=[32], lr=1e-2,\n",
    "          epochs=50, max_steps_per_epoch=30, \n",
    "          batch_size=5000, min_episodes_per_epoch=0, render=False):\n",
    "\n",
    "    \n",
    "    def compress_obs(obs, pov_channel=0, canny_sigma=1.):\n",
    "        angle = obs[\"compassAngle\"]\n",
    "        im = obs[\"pov\"][..., pov_channel]\n",
    "        #im = feature.canny(im, sigma=canny_sigma)\n",
    "        obs = np.append(im.flatten(), angle)\n",
    "        return obs\n",
    "\n",
    "    obs_dim = 1 + obs[\"pov\"].shape[0] * obs[\"pov\"].shape[1]\n",
    "    actions = [{\"forward\" : 1, \"camera\" : [0, 0]},\n",
    "                {\"camera\" : [0, 90]}]\n",
    "    n_acts = len(actions)\n",
    "\n",
    "    # make core of policy network\n",
    "    if logits_net is None:\n",
    "        logits_net = mlp(sizes=[obs_dim]+hidden_sizes+[n_acts])\n",
    "\n",
    "    # make function to compute action distribution\n",
    "    def get_policy(obs):\n",
    "        logits = logits_net(obs)\n",
    "        return Categorical(logits=logits)\n",
    "\n",
    "    # make action selection function (outputs int actions, sampled from policy)\n",
    "    def get_action(obs):\n",
    "        return get_policy(obs).sample().item()\n",
    "\n",
    "    # make loss function whose gradient, for the right data, is policy gradient\n",
    "    def compute_loss(obs, act, weights):\n",
    "        logp = get_policy(obs).log_prob(act)\n",
    "        return -(logp * weights).mean()\n",
    "\n",
    "    # make optimizer\n",
    "    optimizer = Adam(logits_net.parameters(), lr=lr)\n",
    "\n",
    "    # for training policy\n",
    "    def train_one_epoch():\n",
    "        # make some empty lists for logging.\n",
    "        batch_obs = []          # for observations\n",
    "        batch_acts = []         # for actions\n",
    "        batch_weights = []      # for R(tau) weighting in policy gradient\n",
    "        batch_rets = []         # for measuring episode returns\n",
    "        batch_lens = []         # for measuring episode lengths\n",
    "\n",
    "        # reset episode-specific variables\n",
    "        obs = env.reset()       # first obs comes from starting distribution\n",
    "        obs = compress_obs(obs)\n",
    "                    \n",
    "        if render:\n",
    "            env.render()\n",
    "        \n",
    "        done = False            # signal from environment that episode is over\n",
    "        ep_rews = []            # list for rewards accrued throughout ep\n",
    "\n",
    "\n",
    "        # collect experience by acting in the environment with current policy\n",
    "        nbr_actions = 0\n",
    "        while True:\n",
    "\n",
    "\n",
    "            # save obs\n",
    "            batch_obs.append(obs.copy())\n",
    "\n",
    "            # act in the environment\n",
    "            act = get_action(torch.as_tensor(obs, dtype=torch.float32))\n",
    "            nbr_actions += 1\n",
    "            \n",
    "            obs, rew, done, _ = env.step(actions[act])\n",
    "            obs = compress_obs(obs)\n",
    "            \n",
    "            if render:\n",
    "                env.render()\n",
    "\n",
    "            # save action, reward\n",
    "            batch_acts.append(act)\n",
    "            ep_rews.append(rew)\n",
    "\n",
    "            if nbr_actions >= max_steps_per_epoch or done:\n",
    "                # if episode is over, record info about episode\n",
    "                ep_ret, ep_len = sum(ep_rews), len(ep_rews)\n",
    "                batch_rets.append(ep_ret)\n",
    "                batch_lens.append(ep_len)\n",
    "\n",
    "                # the weight for each logprob(a|s) is R(tau)\n",
    "                batch_weights += [ep_ret] * ep_len\n",
    "\n",
    "                # reset episode-specific variables\n",
    "                obs, done, ep_rews, nbr_actions = env.reset(), False, [], 0\n",
    "                obs = compress_obs(obs)\n",
    "\n",
    "                # end experience loop if we have enough of it\n",
    "                if (len(batch_obs) > batch_size) and \\\n",
    "                  (len(batch_rets) >= min_episodes_per_epoch):\n",
    "                    break\n",
    "\n",
    "        # take a single policy gradient update step\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss = compute_loss(obs=torch.as_tensor(batch_obs, dtype=torch.float32),\n",
    "                                  act=torch.as_tensor(batch_acts, dtype=torch.int32),\n",
    "                                  weights=torch.as_tensor(batch_weights, dtype=torch.float32)\n",
    "                                  )\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        return batch_loss, batch_rets, batch_lens\n",
    "\n",
    "    # training loop\n",
    "    for i in range(epochs):\n",
    "        batch_loss, batch_rets, batch_lens = train_one_epoch()\n",
    "        print(('epoch: %3d \\t loss: %.3f \\t avg_return: %.3f' +\n",
    "                '\\t avg_episode_len: %.3f \\t epoch_len: %3d')%\n",
    "                (i, batch_loss, np.mean(batch_rets), np.mean(batch_lens), len(batch_rets)))\n",
    "        \n",
    "    return logits_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 \t loss: -0.630 \t avg_return: -0.983\t avg_episode_len: 100.000 \t epoch_len:   6\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "epochs = 5\n",
    "batch_size = 500\n",
    "max_steps_per_epoch=100\n",
    "\n",
    "mlp = train(env=env, render=False, lr=learning_rate,\n",
    "          epochs=epochs, max_steps_per_epoch=max_steps_per_epoch,\n",
    "          batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
